{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is an interactive file for transforming the raw t-cell/dcell dataset into compressed files.\n",
    "\n",
    "## The issue comes from high RAM usage both locally and in Google Colab.\n",
    "\n",
    "## Input format:\n",
    "- A folder containing images \n",
    "- Each image has a counterpart: for each \"filename\" (letter - digit), there is a red image, and a green image\n",
    "- red image = tcell\n",
    "- green image = dendritic cell\n",
    "- we need both the separated images (B&W) and the combined images (RGB)\n",
    "- Each image is 2048x2048 8MB TIFF image\n",
    "\n",
    "## Steps\n",
    "1. Pass a 192x192 sliding window over the images. \n",
    "2. Store the filenames\n",
    "3. Take each of the reduced images, and combine them to create RGB images (red channel = tcell, green channel = dcell)\n",
    "4. Calculate the intersection over union overlap for each image and store it in a file.\n",
    "\n",
    "## Output:\n",
    "**DATA_full.npz**\n",
    "- x: raw images \n",
    "- y: raw filename names (there will be duplicates)   \n",
    "\n",
    "**DATA_overlaps.npz**\n",
    "- y_overlaps : overlap value for RGB image \n",
    "\n",
    "### The reason I am not combining tcell+dcell in a RGB dataset is because doing that resulted in a 13Gig dataset (3 times as big) that I cannot send to Google Drive, which I use to train models with a GPU through Colab.\n",
    "### Hence the original, unmodified images need to be kept to be processed in-notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: pass a sliding window over the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset_helpers import read_folder_filenames, is_dmso\n",
    "from dataset_helpers import sliding_window\n",
    "\n",
    "from skimage.io import imread\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress_images(out, filenames, size):\n",
    "    \"\"\"\n",
    "    returns:\n",
    "    a npz file of:\n",
    "     - image arrays in shape (size, size, 1)\n",
    "     - filenames (unmodified)\n",
    "    \n",
    "    @parameters:\n",
    "    out = name of the outputted compressed file\n",
    "    filenames = all filenames of files to compress\n",
    "    size = size of output images \n",
    "    \n",
    "    \n",
    "    @assumptions:\n",
    "    * validity of filenames has been checked\n",
    "    \"\"\"\n",
    "    \n",
    "    compressed = []\n",
    "    fn = []\n",
    "    \n",
    "    for file in filenames:\n",
    "        img = imread(file)\n",
    "        windows = sliding_window(img, size)\n",
    "        img = None\n",
    "        for img in windows:\n",
    "            compressed.append(img)\n",
    "            fn.append(file)\n",
    "            img = None\n",
    "        windows = None\n",
    "    \n",
    "    compressed = np.array(compressed)\n",
    "    fn = np.array(fn)\n",
    "    np.savez(out, x=compressed, y=fn)\n",
    "    \n",
    "    print(\"All files compressed into %s\" % out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filenames = sorted(read_folder_filenames(your_folder_here))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = '/Volumes/TARDIS/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CK19_files = sorted(read_folder_filenames(folder+\"CK19\"))\n",
    "CK21_files = sorted(read_folder_filenames(folder+\"CK21\"))\n",
    "CK22_files = sorted(read_folder_filenames(folder+\"CK22_half\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = sorted([CK19_files, CK21_files, CK22_files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DMSO_files = []\n",
    "for file in all_files:\n",
    "    if is_dmso(file):\n",
    "        DMSO_files.append(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take into consideration before running:\n",
    "* this will take A LOT of memory\n",
    "* laptop struggles on 8MB of ram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compress_images(\"your_output\", your_files, your_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compress_images(\"/Volumes/TARDIS/CK19_full.npz\", CK19_files, 192)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compress_images(\"/Volumes/TARDIS/DMSO_full.npz\", DMSO_files, 192)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files compressed into /Volumes/TARDIS/CK22_half.npz\n"
     ]
    }
   ],
   "source": [
    "compress_images(\"/Volumes/TARDIS/CK22_half.npz\", CK22_files, 192)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Capture overlap metrics from combined images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#npzfile = np.load(\"your_npz_file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "npzfile = np.load(\"/Volumes/TARDIS/CK22_full.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = npzfile['x']\n",
    "filenames = npzfile['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset_helpers import combine_images\n",
    "from segmentation import get_mask, iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined images, associated label\n",
    "x_combined, y_combined = combine_images(x, filenames, mask=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_overlaps(x, y):\n",
    "    overlaps = np.ndarray(shape=(len(x),), dtype=np.float32) # overlap values - combined\n",
    "\n",
    "    # initialise index values\n",
    "    i = 0\n",
    "\n",
    "    print(\"Looping through images...\")\n",
    "    while i < len(x):\n",
    "        if y[i] == 3:\n",
    "            # image is faulty\n",
    "            overlaps[i] = 0\n",
    "        else:\n",
    "            overlaps[i] = iou(get_mask(x[i, ..., 1]), get_mask(x[i, ..., 0]))\n",
    "\n",
    "        i += 1\n",
    "    return overlaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_overlaps = get_overlaps(x_combined, y_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = \"/Volumes/TARDIS/CK22_overlaps.npz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(out, overlaps=y_overlaps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
