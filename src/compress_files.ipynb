{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is an interactive file for transforming the raw t-cell/dcell dataset into compressed files.\n",
    "\n",
    "## The issue comes from high RAM usage both locally and in Google Colab.\n",
    "\n",
    "## Input format:\n",
    "- A folder containing images \n",
    "- Each image has a counterpart: for each \"filename\" (letter - digit), there is a red image, and a green image\n",
    "- red image = tcell\n",
    "- green image = dendritic cell\n",
    "- we need both the separated images (B&W) and the combined images (RGB)\n",
    "- Each image is 2048x2048 8MB TIFF image\n",
    "\n",
    "## Steps\n",
    "1. Pass a 192x192 sliding window over the images. \n",
    "2. Store the filenames\n",
    "3. Take each of the reduced images, and combine them to create RGB images (red channel = tcell, green channel = dcell)\n",
    "4. Calculate the intersection over union overlap for each image and store it in a file.\n",
    "\n",
    "## Output:\n",
    "**DATA_full.npz**\n",
    "- x: raw images \n",
    "- y: raw filename names (there will be duplicates)   \n",
    "\n",
    "**DATA_overlaps.npz**\n",
    "- y_overlaps : overlap value for RGB image \n",
    "\n",
    "### The reason I am not combining tcell+dcell in a RGB dataset is because doing that resulted in a 13Gig dataset (3 times as big) that I cannot send to Google Drive, which I use to train models with a GPU through Colab.\n",
    "### Hence the original, unmodified images need to be kept to be processed in-notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: pass a sliding window over the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset_helpers import read_folder_filenames\n",
    "from config import repo_path, imw\n",
    "\n",
    "from skimage.io import imread\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(img, dest_size, rgb=False):\n",
    "    \"\"\"\n",
    "    This function passes a sliding window over an image\n",
    "    and returns sub-images\n",
    "    --> more detail\n",
    "    --> more training data\n",
    "    \"\"\"\n",
    "\n",
    "    new_img = np.full_like(img, img)\n",
    "\n",
    "    size = img.shape[0]\n",
    "    if dest_size > size or dest_size % 2 != 0:\n",
    "        raise Exception(\n",
    "            \"destination size is bigger than picture size or destination size is not even\")\n",
    "\n",
    "    qty = size // dest_size\n",
    "    if size % dest_size != 0:\n",
    "        # need to crop out the left and bottom (less significant in dataset)\n",
    "        crop = size - dest_size * qty\n",
    "        new_img = new_img[crop:, :-crop]\n",
    "\n",
    "    if rgb:\n",
    "        windows = np.ndarray(\n",
    "            shape=(qty**2, dest_size, dest_size, 3), dtype=np.uint16)\n",
    "    else:\n",
    "        windows = np.ndarray(\n",
    "            shape=(qty**2, dest_size, dest_size), dtype=np.uint16)\n",
    "\n",
    "    i = 0\n",
    "    for row in range(qty):\n",
    "        y = row * dest_size\n",
    "        x = 0\n",
    "        for col in range(qty):\n",
    "            #print(\"x:coord {},{} - y:coord {},{}\".format(x, x+dest_size, y, y+dest_size))\n",
    "            windows[i] = new_img[x:x + dest_size, y:y + dest_size]\n",
    "            x += dest_size\n",
    "            i += 1\n",
    "\n",
    "    return windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress_images(out, filenames, size):\n",
    "    \"\"\"\n",
    "    returns:\n",
    "    a npz file of:\n",
    "     - image arrays in shape (size, size, 1)\n",
    "     - filenames (unmodified)\n",
    "    \n",
    "    @parameters:\n",
    "    out = name of the outputted compressed file\n",
    "    filenames = all filenames of files to compress\n",
    "    size = size of output images \n",
    "    \n",
    "    \n",
    "    @assumptions:\n",
    "    * validity of filenames has been checked\n",
    "    \"\"\"\n",
    "    \n",
    "    compressed = []\n",
    "    fn = []\n",
    "    \n",
    "    for file in filenames:\n",
    "        img = imread(file)\n",
    "        windows = sliding_window(img, size)\n",
    "        img = None\n",
    "        for img in windows:\n",
    "            compressed.append(img)\n",
    "            fn.append(file)\n",
    "            img = None\n",
    "        windows = None\n",
    "    \n",
    "    compressed = np.array(compressed)\n",
    "    fn = np.array(fn)\n",
    "    np.savez(out, x=compressed, y=fn)\n",
    "    \n",
    "    print(\"All files compressed into %s\" % out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = sorted(read_folder_filenames(repo_path + 'data/sample_data/raw/images'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files compressed into /Users/Leonore/Documents/Workspace/l4proj/data/sample_data/processed/sample_images.npz\n"
     ]
    }
   ],
   "source": [
    "compress_images(repo_path + 'data/sample_data/processed/sample_images.npz', filenames, imw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Capture overlap metrics from combined images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "npzfile = np.load(repo_path + 'data/sample_data/processed/sample_images.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = npzfile['x']\n",
    "filenames = npzfile['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3600"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset_helpers import combine_images\n",
    "from segmentation import get_mask, iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images preprocessed. Size of dataset: 1800\n"
     ]
    }
   ],
   "source": [
    "# combined images, associated label\n",
    "x_combined, y_combined = combine_images(x, filenames, mask=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_overlaps(x, y):\n",
    "    overlaps = np.ndarray(shape=(len(x),), dtype=np.float32) # overlap values - combined\n",
    "\n",
    "    # initialise index values\n",
    "    i = 0\n",
    "\n",
    "    print(\"Looping through images...\")\n",
    "    while i < len(x):\n",
    "        if y[i] == 3:\n",
    "            # image is faulty\n",
    "            overlaps[i] = 0\n",
    "        else:\n",
    "            overlaps[i] = iou(get_mask(x[i, ..., 1]), get_mask(x[i, ..., 0]))\n",
    "\n",
    "        i += 1\n",
    "    return overlaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looping through images...\n"
     ]
    }
   ],
   "source": [
    "y_overlaps = get_overlaps(x_combined, y_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = repo_path + 'data/sample_data/processed/sample_overlaps.npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(out, overlaps=y_overlaps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
