{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is an interactive file for transforming the raw t-cell/dcell dataset into compressed files. This can take a load on a low-RAM computer for big datasets.\n",
    "\n",
    "### Input format:\n",
    "- A folder containing images \n",
    "- Each image has a counterpart: for each \"filename\" (letter - digit), there is a red image, and a green image\n",
    "- red image = tcell\n",
    "- green image = dendritic cell\n",
    "- we need both the separated images (B&W) and the combined images (RGB)\n",
    "- Each image is 2048x2048 8MB TIFF image\n",
    "\n",
    "### Steps\n",
    "1. Pass a 192x192 sliding window over the images. (or else, set in config.py) \n",
    "2. Store the filenames\n",
    "3. Take each of the reduced images, and combine them to create RGB images (red channel = tcell, green channel = dcell)\n",
    "4. Calculate the intersection over union overlap for each image \n",
    "5. Store the combined images, overlap values, combined labels, and filenames in a file for development\n",
    "\n",
    "### Output:\n",
    "**DATA_combined.npz**\n",
    "- x_combined: combined patches of images \n",
    "- y_combined: labels for combined images\n",
    "- y_overlaps: overlap values for combined images \n",
    "- filenames: raw filenames for un-combined images (for debugging and labelling purposes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: pass a sliding window over the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset_helpers import read_folder_filenames\n",
    "from config import repo_path, imw\n",
    "\n",
    "from skimage.io import imread\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(img, dest_size, rgb=False):\n",
    "    \"\"\"\n",
    "    This function passes a sliding window over an image\n",
    "    and returns sub-images\n",
    "    --> more detail\n",
    "    --> more training data\n",
    "    \"\"\"\n",
    "\n",
    "    new_img = np.full_like(img, img)\n",
    "\n",
    "    size = img.shape[0]\n",
    "    if dest_size > size or dest_size % 2 != 0:\n",
    "        raise Exception(\n",
    "            \"destination size is bigger than picture size or destination size is not even\")\n",
    "\n",
    "    qty = size // dest_size\n",
    "    if size % dest_size != 0:\n",
    "        # need to crop out the left and bottom (less significant in dataset)\n",
    "        crop = size - dest_size * qty\n",
    "        new_img = new_img[crop:, :-crop]\n",
    "\n",
    "    if rgb:\n",
    "        windows = np.ndarray(\n",
    "            shape=(qty**2, dest_size, dest_size, 3), dtype=np.uint16)\n",
    "    else:\n",
    "        windows = np.ndarray(\n",
    "            shape=(qty**2, dest_size, dest_size), dtype=np.uint16)\n",
    "\n",
    "    i = 0\n",
    "    for row in range(qty):\n",
    "        y = row * dest_size\n",
    "        x = 0\n",
    "        for col in range(qty):\n",
    "            #print(\"x:coord {},{} - y:coord {},{}\".format(x, x+dest_size, y, y+dest_size))\n",
    "            windows[i] = new_img[x:x + dest_size, y:y + dest_size]\n",
    "            x += dest_size\n",
    "            i += 1\n",
    "\n",
    "    return windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def images_to_patches(filenames, size):\n",
    "    \"\"\"\n",
    "    returns:\n",
    "    @image arrays in shape (size, size, 1)\n",
    "    @filenames (unmodified)\n",
    "    \n",
    "    @parameters:\n",
    "    filenames = all filenames of files to compress\n",
    "    size = size of output images \n",
    "    \n",
    "    @assumptions:\n",
    "    * validity of filenames has been checked\n",
    "    \"\"\"\n",
    "    \n",
    "    patches = []\n",
    "    fn = []\n",
    "    \n",
    "    for file in filenames:\n",
    "        img = imread(file)\n",
    "        windows = sliding_window(img, size)\n",
    "        img = None\n",
    "        for img in windows:\n",
    "            patches.append(img)\n",
    "            fn.append(file)\n",
    "            img = None\n",
    "        windows = None\n",
    "    \n",
    "    patches = np.array(patches)\n",
    "    fn = np.array(fn)\n",
    "    \n",
    "    print(\"All files turned into patches of size {}\".format(size))\n",
    "    return patches, fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = sorted(read_folder_filenames(repo_path + 'data/sample_data/raw/images'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files turned into patches of size 192\n"
     ]
    }
   ],
   "source": [
    "x, filenames = images_to_patches(filenames, imw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Combined images and capture metrics from the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset_helpers import combine_images\n",
    "from segmentation import get_mask, iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images preprocessed. Size of dataset: 1800\n"
     ]
    }
   ],
   "source": [
    "# combined images, associated label\n",
    "x_combined, y_combined = combine_images(x, filenames, mask=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looping through images...\n",
      "Overlaps have been counted\n"
     ]
    }
   ],
   "source": [
    "def get_overlaps(x, y):\n",
    "    overlaps = np.ndarray(shape=(len(x),), dtype=np.float32) # overlap values - combined\n",
    "\n",
    "    # initialise index values\n",
    "    i = 0\n",
    "\n",
    "    print(\"Looping through images...\")\n",
    "    while i < len(x):\n",
    "        if y[i] == 3:\n",
    "            # image is faulty\n",
    "            overlaps[i] = 0\n",
    "        else:\n",
    "            overlaps[i] = iou(get_mask(x[i, ..., 1]), get_mask(x[i, ..., 0]))\n",
    "\n",
    "        i += 1\n",
    "    return overlaps\n",
    "\n",
    "y_overlaps = get_overlaps(x_combined, y_combined)\n",
    "print(\"Overlaps have been counted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed(repo_path + 'data/sample_data/processed/sample_combined.npz', \n",
    "                    x_combined=x_combined, y_combined=y_combined, y_overlaps=y_overlaps, filenames=filenames)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
