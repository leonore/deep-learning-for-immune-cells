{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is an interactive file for transforming the raw t-cell/dcell dataset into compressed files.\n",
    "\n",
    "## Input format:\n",
    "- A folder containing images \n",
    "- Each image has a counterpart: for each \"filename\" (letter - digit), there is a red image, and a green image\n",
    "- red image = tcell\n",
    "- green image = dendritic cell\n",
    "- we need both the separated images (B&W) and the combined images (RGB)\n",
    "- Each image is 2048x2048 8MB TIFF image\n",
    "\n",
    "## Steps\n",
    "1. Pass a 192x192 sliding window over the images. \n",
    "2. Store the filenames\n",
    "3. Take each of the reduced images, and combine them to create RGB images (red channel = tcell, green channel = dcell)\n",
    "4. While doing this process, store the corresponding category labels in a file and calculate the intersection over union overlap.\n",
    "\n",
    "## Output:\n",
    "**DATA_full.npz**\n",
    "- x: raw images \n",
    "- y: raw filename names (there will be duplicates)   \n",
    "\n",
    "**DATA_metrics.npz**\n",
    "- y_combined : label for corresponding filenames (Unstimulated, OVA, ConA, Faulty)\n",
    "- y_overlaps : overlap value for RGB image \n",
    "- y_no_faulty : label for corresponding filenames, but Faulty images are not singled out \n",
    "\n",
    "### The reason I am not combining tcell+dcell in a RGB dataset is because doing that resulted in a 13Gig dataset (3 times as big) that I cannot send to Google Drive, which I use to train models with a GPU through Colab.\n",
    "### Hence the original, unmodified images need to be kept to be processed in-notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: pass a sliding window over the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset_helpers import read_folder_filenames, is_dmso\n",
    "from dataset_helpers import sliding_window\n",
    "\n",
    "from skimage.io import imread\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress_images(out, filenames, size):\n",
    "    \"\"\"\n",
    "    returns:\n",
    "    a npz file of:\n",
    "     - image arrays in shape (size, size, 1)\n",
    "     - filenames (unmodified)\n",
    "    \n",
    "    @parameters:\n",
    "    out = name of the outputted compressed file\n",
    "    filenames = all filenames of files to compress\n",
    "    size = size of output images \n",
    "    \n",
    "    \n",
    "    @assumptions:\n",
    "    * validity of filenames has been checked\n",
    "    \"\"\"\n",
    "    \n",
    "    compressed = []\n",
    "    fn = []\n",
    "    \n",
    "    for file in filenames:\n",
    "        img = imread(file)\n",
    "        windows = sliding_window(img, size)\n",
    "        img = None\n",
    "        for img in windows:\n",
    "            compressed.append(img)\n",
    "            fn.append(file)\n",
    "            img = None\n",
    "        windows = None\n",
    "    \n",
    "    compressed = np.array(compressed)\n",
    "    fn = np.array(fn)\n",
    "    np.savez(out, x=compressed, y=fn)\n",
    "    \n",
    "    print(\"All files compressed into %s\" % out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filenames = sorted(read_folder_filenames(your_folder_here))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = '/Volumes/TARDIS/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CK19_files = sorted(read_folder_filenames(folder+\"CK19\"))\n",
    "CK21_files = sorted(read_folder_filenames(folder+\"CK21\"))\n",
    "CK22_files = sorted(read_folder_filenames(folder+\"CK22\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = sorted([CK19_files, CK21_files, CK22_files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DMSO_files = []\n",
    "for file in all_files:\n",
    "    if is_dmso(file):\n",
    "        DMSO_files.append(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take into consideration before running:\n",
    "* this will take A LOT of memory\n",
    "* laptop struggles on 8MB of ram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compress_images(\"your_output\", your_files, your_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compress_images(\"/Volumes/TARDIS/CK19_full.npz\", CK19_files, 192)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compress_images(\"/Volumes/TARDIS/DMSO_full.npz\", DMSO_files, 192)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compress_images(\"/Volumes/TARDIS/CK22_full.npz\", CK22_files, 192)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Capture metrics from combined images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#npzfile = np.load(\"your_npz_file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "npzfile = np.load(\"/Volumes/TARDIS/CK22_full.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = npzfile['x']\n",
    "filenames = npzfile['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset_helpers import is_faulty, minmax, low_clip, get_label\n",
    "from segmentation import get_mask, iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capture_metrics(x, y):\n",
    "    assert len(x) == len(y)\n",
    "    y_combined = np.ndarray(shape=(len(x)//2), dtype=np.uint32) # labels - combined\n",
    "    y_no_faulty = np.ndarray(shape=(len(x)//2), dtype=np.uint8) # labels without faulty - combined\n",
    "    overlaps = np.ndarray(shape=(len(x)//2), dtype=np.float32) # overlap values - combined\n",
    "\n",
    "    # initialise index values\n",
    "    idx = 0\n",
    "    i = 0\n",
    "    count = 0\n",
    "\n",
    "    print(\"Looping through images...\")\n",
    "    while idx < len(x)-100:\n",
    "        # ignore 100, 300, etc. values as they will already have been processed\n",
    "        if count == 100:\n",
    "            count = 0\n",
    "            idx += 100\n",
    "        else:\n",
    "\n",
    "            if is_faulty(x[idx]) or is_faulty(x[idx+100]):\n",
    "                y_combined[i] = 3\n",
    "                y_no_faulty[i] = get_label(y[idx])\n",
    "                overlaps[i] = 0\n",
    "            else:\n",
    "                y_combined[i] = get_label(y[idx])\n",
    "                y_no_faulty[i] = get_label(y[idx])\n",
    "                tcell = get_mask(minmax(low_clip(x[idx].astype(np.float32))))\n",
    "                dcell = get_mask(minmax(low_clip(x[idx + 100].astype(np.float32))))\n",
    "                overlaps[i] = iou(tcell,dcell)\n",
    "\n",
    "            tcell = None\n",
    "            dcell = None\n",
    "            \n",
    "            x[idx] = 0\n",
    "            x[idx+100] = 0\n",
    "\n",
    "            i += 1\n",
    "            idx += 1\n",
    "            count += 1\n",
    "    return y_combined, y_no_faulty, overlaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looping through images...\n"
     ]
    }
   ],
   "source": [
    "y_combined, y_no_faulty, y_overlaps = capture_metrics(x, filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#out = \"your_out_file\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = \"/Volumes/TARDIS/CK22_metrics.npz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(out, y_combined=y_combined, y_no_faulty=y_no_faulty, y_overlaps=y_overlaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
