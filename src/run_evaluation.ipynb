{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "run_evaluation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FFO1u1pjgrx",
        "colab_type": "text"
      },
      "source": [
        "# Evaluation: deep learning for analysing immune cell interactions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNTEZMogjXGe",
        "colab_type": "text"
      },
      "source": [
        "## Colab file setup\n",
        "don't run this if on local"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwvQ1GwQjpGk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oY3j4GwSjsNe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/gdrive/My Drive/l4_project')\n",
        "sys.path.append('/content/gdrive/My Drive/l4_project/src')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PK5zKQEZcw6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/gdrive/My Drive/l4_project/src"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIlDXmOyi9Ob",
        "colab_type": "code",
        "outputId": "64ddfc34-02fb-4670-c785-942349597cd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWcn8vZxjprU",
        "colab_type": "text"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9b9fIjXtjwLo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow.keras\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trCfEgYFwcBz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# (hopefully) disable tensorflow 2.0 warnings\n",
        "import tensorflow as tf\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "# disable annoying UMAP numba warnings (bad for readability)\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMiCrUOPYuXI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from models import make_autoencoder, make_regression, train\n",
        "from models import evaluate_regression, evaluate_autoencoder\n",
        "from clustering import run_both, umap_fn\n",
        "\n",
        "from evaluation_helpers import plot_clusters, show_image\n",
        "from dataset_helpers import get_label, combine_images, efficient_shuffle, remove_faulty\n",
        "\n",
        "# WARNING: evaluation_path, repo_path will have to be changed if running on your own machine\n",
        "from config import RS, evaluation_path, repo_path"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dp2-EvGvlZ5L",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation parameters\n",
        "Change this for all the different datasets to evaluate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQbqPQIWIHU7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mask = False # use True if background-correcting the images \n",
        "data_file = repo_path + \"data/sample_data/processed/sample_images.npz\"\n",
        "metrics_file = repo_path + \"data/sample_data/processed/sample_overlaps.npz\"\n",
        "if mask:\n",
        "    weights = [repo_path + \"data/weights/decoder_masked.h5\",\n",
        "            repo_path + \"data/weights/encoder_masked.h5\",\n",
        "            repo_path + \"data/weights/regression_masked.h5\"]\n",
        "else:\n",
        "    weights = [repo_path + \"data/weights/decoder.h5\",\n",
        "            repo_path + \"data/weights/encoder.h5\",\n",
        "            repo_path + \"data/weights/regression.h5\"]\n",
        "# weights = None to train a new model\n",
        "tag = \"sample\" "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNWCZjH_m0Zm",
        "colab_type": "text"
      },
      "source": [
        "## Load and pre-process data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVt_jJr3nBzw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get images\n",
        "print(\"{} is being loaded\".format(data_file))\n",
        "data = np.load(data_file)\n",
        "x = data['x']\n",
        "filenames = data['y']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgfelqGym2J0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# preprocess\n",
        "print(\"Combining images.\")\n",
        "x_combined, y_combined = combine_images(x, filenames, mask=mask)\n",
        "x = None # save memory"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t12xELcUuQCS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Overlap metrics are being loaded from {}\".format(metrics_file))\n",
        "metrics = np.load(metrics_file)\n",
        "y_overlaps = metrics['overlaps']*100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfcSHwWCMLQa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_no_faulty = remove_faulty(filenames) # remove faulty labels for regression evaluation\n",
        "\n",
        "efficient_shuffle(x_combined, y_combined, y_overlaps, y_no_faulty, random_state=RS)\n",
        "\n",
        "assert len(x_combined) == len(y_combined) == len(y_overlaps) == len(y_no_faulty)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxfFIJ7tnl7y",
        "colab_type": "text"
      },
      "source": [
        "## Build the autoencoder and regression models\n",
        "Either from weights or training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3rQ6xpFnz8U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if weights:\n",
        "    print(\"Decoder file is {}\".format(weights[0]))\n",
        "    decoder = load_model(weights[0])\n",
        "    print(\"Encoder file is {}\".format(weights[1]))\n",
        "    encoder = load_model(weights[1], compile=False)\n",
        "    print(\"Regression file is {}\".format(weights[2]))\n",
        "    regression = load_model(weights[2])\n",
        "else:\n",
        "    x_train, x_test, y_train, y_test = x_combined[:-1000], x_combined[-1000:], y_combined[:-1000], y_combined[-1000:]\n",
        "\n",
        "    # not recommended on local - could take hours and strain memory\n",
        "    print(\"Training autoencoder... be aware this might take a long time\")\n",
        "    decoder, encoder = make_autoencoder()\n",
        "    train(decoder, x_train, x_train, tag=tag)\n",
        "\n",
        "    print(\"Training regression model... be aware this might take a long time\")\n",
        "    regression = make_regression(encoder)\n",
        "    train(regression, x_train, y_train, tag=tag)\n",
        "\n",
        "    decoder.save('decoder_{}.h5'.format(tag))\n",
        "    encoder.save('encoder_{}.h5'.format(tag))\n",
        "    regression.save('regression_{}.h5'.format(tag))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h82YgaLYoq5g",
        "colab_type": "text"
      },
      "source": [
        "## Evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eca5gBTupDg-",
        "colab_type": "text"
      },
      "source": [
        "### Evaluate autoencoder:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pS235lxvwSiM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "evaluate_autoencoder(decoder, x_combined, tag=tag)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGhzIXk_Bo1C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# run clustering\n",
        "encoded_imgs = encoder.predict(x_combined)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iloN0EXYThi",
        "colab_type": "code",
        "outputId": "b6be0a3d-8915-424e-9c98-b1bc476708b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "x_umap = umap_fn(encoded_imgs, random_state=RS, n_neighbors=30, min_dist=0.8)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clustering encoded images\n",
            "UMAP dimensionality reduction started at 14:03:01\n",
            "UMAP took 0:00:25.626747 to finish\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-cqYtX3sV2i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_clusters(x_umap, y_combined, labels=[\"OVA\", \"ConA\"], tag=tag+'_umap')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vyz1wPtxXhcG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_clusters_with_size(X, y, s, labels=[\"Unstimulated\", \"OVA\", \"ConA\"], tag=None):\n",
        "    targets = np.unique(y)\n",
        "    shades = np.array(sns.color_palette(\"hls\", len(labels)))\n",
        "\n",
        "    y = np.array(y)\n",
        "\n",
        "    fig = plt.figure(figsize=(15,15))\n",
        "    ax = plt.subplot()\n",
        "\n",
        "    for target, color, label in zip(targets, shades, labels):\n",
        "        sc = plt.scatter(X[y==target, 0], X[y==target, 1], c=[color], s=(s[y==target]+1)*10, label=label, edgecolor=\"k\", lw=0.2, alpha=0.75)\n",
        "\n",
        "    plt.legend(loc='lower right', fontsize='x-large')\n",
        "    ax.axis('off')\n",
        "    ax.grid(False)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    if tag:\n",
        "        plt.savefig(evaluation_path + \"clustering/\" + tag + \".png\", dpi=300)\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0ZHVPuQXp__",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_clusters_with_size(x_umap, y_combined, y_overlaps, labels=[\"OVA\", \"ConA\"], tag=tag+'_umap_size')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syXzsDpVpGqZ",
        "colab_type": "text"
      },
      "source": [
        "### Evaluate regression:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCQKclUgpJf8",
        "colab_type": "code",
        "outputId": "49bd3ba9-09b0-4fea-b343-3067208b73ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# run regression\n",
        "print(\"Running regression using encoder model...\")\n",
        "\n",
        "y_pred = regression.predict(x_combined)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running regression using encoder model...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCJH2Co8LISa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "evaluate_regression(y_overlaps, y_pred, y_no_faulty, labels=[\"OVA\", \"ConA\"], tag=tag)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}