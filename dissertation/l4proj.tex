% REMEMBER: You must not plagiarise anything in your report. Be extremely careful.

\documentclass{l4proj}


%
% put any additional packages here
%

\begin{document}

%==============================================================================
%% METADATA
\title{Deep learning for analysing immune cell interactions}
\author{Leonore Papaloizos}
\date{\today}

\maketitle

%==============================================================================
%% ABSTRACT
\begin{abstract}
    Motivate; set aims; describe work; explain results.
    \vskip 0.5em
    ``XYZ is bad. This project investigated ABC to determine if it was better.
    ABC used XXX and YYY to implement ZZZ. This is particularly interesting as XXX and YYY have
    never been used together. It was found that
    ABC was 20\% better than XYZ, though it caused rabies in half of subjects.''
\end{abstract}

%==============================================================================

% EDUCATION REUSE CONSENT FORM
% If you consent to your project being shown to future students for educational purposes
% then insert your name and the date below to  sign the education use form that appears in the front of the document.
% You must explicitly give consent if you wish to do so.
% If you sign, your project may be included in the Hall of Fame if it scores particularly highly.
%
% Please note that you are under no obligation to sign
% this declaration, but doing so would help future students.
%
\def\consentname {Leonore Papaloizos} % your full name
\def\consentdate {\today} % the date you agree
%
\educationalconsent


%==============================================================================
\tableofcontents

%==============================================================================
%% Notes on formatting
%==============================================================================
% The first page, abstract and table of contents are numbered using Roman numerals and are not
% included in the page count.
%
% From now on pages are numbered
% using Arabic numerals. Therefore, immediately after the first call to \chapter we need the call
% \pagenumbering{arabic} and this should be called once only in the document.
%
% Do not alter the bibliography style.
%
% The first Chapter should then be on page 1. You are allowed 40 pages for a 40 credit project and 30 pages for a
% 20 credit report. This includes everything numbered in Arabic numerals (excluding front matter) up
% to but excluding the appendices and bibliography.
%
% You must not alter text size (it is currently 10pt) or alter margins or spacing.
%
%
%==================================================================================================================================
%
% IMPORTANT
% The chapter headings here are **suggestions**. You don't have to follow this model if
% it doesn't fit your project. Every project should have an introduction and conclusion,
% however.
%
%==================================================================================================================================
\chapter{Introduction}

% reset page numbering. Don't remove this!
\pagenumbering{arabic}

\section{Motivation}

[TODO: biological]
The initiation of an immune response in our immune system depends on the interaction strength between different types of immune cells. Interactions between immune cells can be enhanced or inhibited by the application of drugs. Studying the reactions of immune cells to different types of drugs can help direct research in the right direction.

\bigskip
[TODO: technical]
Applying deep learning to the analysis of microscope images of immune cells would allow us to explore cell interaction under different drug conditions. We can study whether deep learning techniques are applicable in this context and the type of high-dimensional data we have been provided by evaluating whether they provide any useful information on interaction levels between immune cells under different experimental conditions.

%==================================================================================================================================
\chapter{Background}

\section{Immunology research}

\section{Autoencoders}

\section{High dimensional visualisation}

%==================================================================================================================================
\chapter{Materials and Methods}

This chapter covers the image materials that were available to analyse, how they were processed, and which methods were applied to them. The details of the implementation of these methods is then discussed in Section \ref{implementation}.

\section{Immune cells dataset}

\subsection{Setup}

[decide where to explain the biological background so you can reconcile explanations: the backing research (finding interaction) as well as the different labels that come with the cells]

\bigskip
The images that were used for the purpose of this research were provided by biological researchers. The images were taken for their own research in an INCell Analyzer Machine, in which you can place a plate of wells for inage capture [ref?]. Each well contains t-cells and dendritic cells, as well as potential compounds to experiment with. In each well, the t-cells are dyed with a green dye, and the dendritic cells are dyed with a red dye. The output of this operation is three field-of-view images:

\begin{itemize}
    \item a Brightfield image, which shows both t-cells and dendritic cells (Figure \ref{fig:brightfield})
    \item an image of all the t-cells, which has been captured thanks to the green dye (Figure \ref{fig:tcells})
    \item an image of all the dendritic cells, which has been captured thanks to the red dye (Figure \ref{fig:dcells}).
\end{itemize}

\bigskip
[One row of three figures here illustrating the images]

\subsection{Picking images}

There was a large amount of images available from different well plates with different experimental conditions. However, each set of images represents about 8GB of data. Moving images about a file system and through disks or cloud filing system represented substantial time and was vulnerable to transfer errors. Hence, a limited number of plates were picked out for training and evaluation to make sure their consistency could be validated. The plates chosen had to be picked while keeping in mind the experimental conditions they represented, to make sure analysing them would yield something useful.

[TODO: explain in more detail if labels haven't been explained earlier on]
\begin{itemize}
    \item The ``DMSO" dataset: [TODO to be read over by Hannah] DMSO is a solvent that helps solubilise the drug compounds in a well as most compounds are not initially water soluble. The drug compounds being more soluble, they should then be able to have more of an impact.
    \item The ``balanced” dataset: this dataset contains an equal number of images in the three categories of stimulation: no drug simulation, stimulation with OVA peptide, and stimulation with ConA. This is to fight issues of class imbalance when training the model.
    \item The simpler dataset, with two categories: this  dataset contains an equal number of images in two categories: no drug simulation, and simulation with OVA peptide. This was picked in the hope that if no results are obtained with 3 categories, a model might be able to perform better with two.
\end{itemize}

\subsection{Preprocessing}
The datasets obtained from this setup consisted of 2048x2048 12-bit images in a 16-bit TIFF file. As mentioned above, each ``image” really consists of a set of three field-of-view images: the t-cells, the dendritic cells, and the Brightfield image. The Brightfield images were used to gain an overview of what the image might look like, but were discarded and not used for analysis.

%Fiji (ImageJ) was used to explore the images as the particular 12-bit format of the image in a TIFF file meant that standard image previewers reproduced the image as all black. Fiji also offered useful tools for testing image pre-processing methods, such as binary filters, thresholding, and background correction.

\bigskip
Each of the images sized about 8MB, and represented 4,194,304 pixels. Each plate had about 400 setups, which corresponds to 800 images when counting both the t-cell image and the dendritic cell images. This represented an issue of very high dimensions to deal with, and little images to feed into any kind of model.

\bigskip
Moreover, initial tryouts of reconstructing images with an autoencoder showed that it struggled with such small details. Figure () shows that even to the naked eye, the small white dots could easily be confused for dust on the screen.

\bigskip
[example figure]

\bigskip
The first idea was to make the images more palatable by a neural network by cutting up a set square subsection of the image. However, this still created an issue of limited input to the dataset. This was improved by passing a sliding window over the image, creating a hundred 192x192 images per file. This quickly expanded the size of the dataset, making it as big as 58000 samples in some cases. Smaller images also made more sense to the naked eye, hence it was assumed that a trained model would perform better with this gridded dataset.

\bigskip
For each subimage, it was then normalised with min-max normalisation to get a [0,1] range of values. From analysing the images, it was also found that a lot of background noise was in the pixel range of [0, 255] before normalisation, so before normalisation values below 255 were clipped.

\subsection{Outlier detection and labelling}

The provided images sometimes contained some noise, coming from issues such as water droplets in the wells. These outlier images were detected because their pixel values seemed to always be between 0 and 255. Instead of removing them from the dataset entirely, it was decided to keep them in to see if a model could make sense of them as a category. These were labelled as "Faulty".

All the images came with an Excel sheet giving information about the plate layout. Each image was given a letter and a name, and the Excel sheet gave information about drug stimulation, compound ID number, or compound concentration. These Excel sheets were not automatically parsable as types of drugs or location in the sheet might vary from one to the next, hence labelling had to be hardcoded and handchecked.

\subsection{Combining images to visualise interaction}
\bigskip

For feeding into a model, the gridded, processed images had to be combined for them to make sense for the task of analysing interaction. For one set of microscopic image in one condition, the t-cell black and white image and the dendritic cell black and white image were combined in an RGB image where the red channel corresponded to the dendritic cell, the green channel corresponded to the t-cell, and the blue channel was left blank.

Figure () illustrates how the processed and combined sub-image might look, for each of the different categories we are trying to look at in this task.

[row of three images here]

\section{Image segmentation}

Image segmentation refers to the process of separating out different parts of interest of an image for different purposes. The purpose of image segmentation applied to this dataset of immune cells was both to attempt to correct any noisy background from the supplied images as well as use image segmentation to obtain numerical data about cells in the images.

\subsection{Background correction}

A common issue for microscopic images obtained systemically through different screening systems is that of a noisy background [ref]. This can usually be corrected through different methods, such as flat field correction or the rolling ball algorithm [ref]. Flat field correction takes a ``neutral” image without anything (i.e. cells) added to it to later use it as a reference image to perform background correction on any other images. However, the provided dataset did not come with a flat field image. As such, alternatives had to be explored.

\bigskip
All the images in the original, uncombined dataset are black and white, with the details of interest (the cells) in bright white spots. However there might be some gray details in the image that the naked eye cannot see immediately, but that could influence how a machine learns. Hence we need a method that will separate out the cell pixels from the background. We can do this by obtaining a binary mask of the image. The white pixels will correspond to the cells, and the dark cells will be the background. We can remove the background of the original image by multiplying it with the mask. Only the cells will remain in the image.

\subsection{Analysing interaction}

By using the above described method, we also obtain a binary mask of the image. This binary mask can be used for further calculations. A common metric for evaluating image segmentation quality is intersection over union [ref]. In our case, we can use this metric to calculate an area of overlap between the two separate images for a t-cell and a dendritic cell, corresponding to the same experimental condition. We can use the concept of overlap to quantify the level of interaction between cells. This number could then be used attached to an image as an input to a regression model in order to evaluate whether we can try a model to recognise a value of interaction from an image.

\section{Autoencoders}

[TODO: this might be covered in background a bit]
Autoencoders are a particular type of neural network that have a symmetrical layer structured around an encoded representation. The aim of an autoencoder is to map an input to its output as close as possible while reducing its dimensions. The hope is that if an image is reduced to a certain number of dimensions, and a neural network is able to reconstruct the original image very closely just based on that compressed representation, then that compressed bottleneck representation of the image should be a good enough, reduced input we can then feed into other models.

\bigskip
[autoencoder figure here]

\subsection{Visualising high dimensional data}

One use for autoencoders and their capacity to reduce dimensions is that it could help the performance of high-dimensional visualisation techniques. High dimensionality visualisation techniques such as t-sne and UMAP can help visualise if there is an inherent structure to the data. This can be used in the context of analysing immune cell interactions by observing whether or not different clusters are found, and whether or not they correspond to different drug conditions. In this case, we would be able to differentiate different levels of interaction from the images.

\subsection{Regression}

We can also use the encoding part of the autoencoder to build a regression model and evaluate whether the model is capable of predicting interaction values from an image.


%==================================================================================================================================

\chapter{Implementation}

%==================================================================================================================================
\chapter{Evaluation}


%==================================================================================================================================
\chapter{Conclusion}

%==================================================================================================================================
%
%
%==================================================================================================================================
%  APPENDICES

\begin{appendices}

\chapter{Appendices}

\end{appendices}

%==================================================================================================================================
%   BIBLIOGRAPHY

% The bibliography style is abbrvnat
% The bibliography always appears last, after the appendices.

\bibliographystyle{abbrvnat}

\bibliography{l4proj}

\end{document}
